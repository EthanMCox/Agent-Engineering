### Task 1
I experimented with several aspects of the AI reasoning, but for the purposes of this assignment, I will summarize my key takeaways. 

First, it was really interesting to see the reasoning output behind the scenes. One of the things I noticed was that the reasoning output frequently exposed logical errors that demonstrated how the AI models aren't truly able to think about things correctly, but after enough thinking, it is still able to produce reasonable end-output, including both correct reasoning and answers in many cases, even when the reasoning itself was sometimes faulty. It makes sense that reasoning is hidden by default because the end product can be less confusing or misleading to users, but the reasoning steps are very interesting for seeing how the model operates. 

On one of the riddles, I instructed the model to provide the answer prior to giving its reasoning. The end output followed this instruction, but the actual reasoning steps did not, reasoning through the answer prior to coming to a conclusion. I found this interesting because it showed a clear difference between the reasoning behind the scenes and the final output. In the final output, it is more important to follow the instructions directly. 

When I gave the model a basic but specific recipe and I asked it to improve it, the higher-reasoning model did a much better job than the low reasoning model. 

### Task 2:
After testing a few of the same prompts with different levels of reasoning, it seemed like medium reasoning models typically cost 2 to 4 times more than low reasoning models, and high reasoning models cost around 3 times more than medium reasoning models. I felt like low and and medium models were both still pretty fast, while high reasoning took significantly longer.

### Task 3: Read Claude's New Constitution
I read both the news release along with parts of the constitution itself. As I read, I tested Claude vs. ChatGpt to see how they would differ when asked questions, such as, "What is your purpose?" and "What are your core values?" It was very obvious that Claude's responses were formed on the basis of its constitution, and it generally seemed more thoughtful and values-oriented than any of the prompts I tried with ChatGpt. Although I have used Claude some in the past, reading the constitution made me want to use the model more.